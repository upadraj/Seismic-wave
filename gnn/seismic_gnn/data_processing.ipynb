{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\incognito\\miniconda3\\envs\\a1_env\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\incognito\\miniconda3\\envs\\a1_env\\Lib\\site-packages\\torch_scatter\\_scatter_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\incognito\\miniconda3\\envs\\a1_env\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\incognito\\miniconda3\\envs\\a1_env\\Lib\\site-packages\\torch_sparse\\_convert_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\..\\\\data\\\\processed\\\\balance_16k\\\\preprocessing\\\\x_train.csv', '..\\\\..\\\\data\\\\processed\\\\balance_16k\\\\preprocessing\\\\y_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# path = f\"data\\processed\\balance_16k\\preprocessing\"\n",
    "path = Path(\"./../../data/processed/balance_16k/preprocessing\")\n",
    "input_paths = [\n",
    "    os.path.join(path, value) for i, value in enumerate(sorted(os.listdir(path)))\n",
    "]\n",
    "print(input_paths)\n",
    "dataframes = [pd.read_csv(file, header=None) for file in input_paths]\n",
    "int_codes, str_label = pd.factorize(dataframes[1][0])\n",
    "\n",
    "# dataframes[0] = dataframes[0].iloc[:500]\n",
    "# int_codes = int_codes[:500]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataframes[0], int_codes, test_size=0.15, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'Pn', 'Lg', 'Pg', 'Sn', 'P']\n"
     ]
    }
   ],
   "source": [
    "station_list = list(pd.unique(dataframes[1][0]))\n",
    "print(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_for_gnn(X, y, num_segments=20):\n",
    "    graphs = []\n",
    "    segment_size = X.shape[1] // num_segments\n",
    "\n",
    "    for row in range(X.shape[0]):\n",
    "        G = nx.Graph()\n",
    "\n",
    "        for node_idx in range(num_segments):\n",
    "            start = node_idx * segment_size\n",
    "            end = (node_idx + 1) * segment_size\n",
    "            node_features = X.iloc[row][start:end]\n",
    "            G.add_node(node_idx, features=node_features)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            for j in range(i + 1, num_segments):\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "        edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "        x = torch.tensor(\n",
    "            [G.nodes[node][\"features\"] for node in G.nodes()], dtype=torch.float\n",
    "        )\n",
    "\n",
    "        graph_data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        graph_data.y = torch.tensor(y[row], dtype=torch.long)\n",
    "\n",
    "        graphs.append(graph_data)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "# s = dataframes[2]#.iloc[:200]\n",
    "# y = int_codes#[:200]\n",
    "graph_train_data = create_graph_for_gnn(X_train, y_train)\n",
    "graph_test_data = create_graph_for_gnn(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[20, 360], edge_index=[2, 190], y=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggreration type as (aggr)\n",
    "\n",
    "epochs = 10, training = 425 samples\n",
    "| Aggregation types| Accuracy|\n",
    "|-------------------|---------|\n",
    "|    'mean'         | 36      |\n",
    "|    'sum' or 'add' | 36      |\n",
    "|   'max'           | 23      |\n",
    "|   'min'           | 23      |\n",
    "| 'median'          | 35      |\n",
    "|   'mul'           | 24      |\n",
    "|   'std'           | 36      |\n",
    "|  'var'            | 36      |\n",
    "| 'softmax'         | 36      |\n",
    "\n",
    "When run on all the sample except testing accuracy is around 20% on average for all of these aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 5806.1659,\n",
      "Epoch 2, Train Loss: 63.9690,\n",
      "Epoch 3, Train Loss: 79.0357,\n",
      "Epoch 4, Train Loss: 1.7754,\n",
      "Epoch 5, Train Loss: 1.7647,\n",
      "Epoch 6, Train Loss: 1.7642,\n",
      "Epoch 7, Train Loss: 1.7653,\n",
      "Epoch 8, Train Loss: 1.7654,\n",
      "Epoch 9, Train Loss: 1.7654,\n",
      "0.18400923654206958\n",
      "tensor(0.1840)\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, aggr='add'):\n",
    "        super(GCN, self, ).__init__()\n",
    "        self.conv1 = GCNConv(360, 64, aggr)\n",
    "        self.conv2 = GCNConv(64, 128, aggr)\n",
    "\n",
    "        self.fc = torch.nn.Linear(2560, 6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = x.view(data.num_graphs, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(graph_train_data, shuffle=True)\n",
    "test_loader = DataLoader(graph_test_data, shuffle=False)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train_loss = train()\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f},\")\n",
    "\n",
    "def evaluate(train_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=6).to(device)\n",
    "    accuracy_metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, dim=1)\n",
    "            # print(f\"Predicted: {predicted}, Actual: {data.y}\")\n",
    "            correct += (predicted == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "            acc += accuracy_metric(predicted, data.y)\n",
    "\n",
    "    return correct / total, acc / len(train_loader)\n",
    "\n",
    "\n",
    "correct, accu = evaluate(train_loader)\n",
    "print(correct)\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_graph(graph_data, title=\"Graph Visualization\"):\n",
    "#     \"\"\"\n",
    "#     Plots the graph created for the GNN.\n",
    "\n",
    "#     Parameters:\n",
    "#     - graph_data: A PyTorch Geometric Data object representing the graph.\n",
    "#     - title: Title of the plot.\n",
    "#     \"\"\"\n",
    "#     # Convert back to networkx for visualization\n",
    "#     G = nx.Graph()\n",
    "\n",
    "#     # Add nodes with features directly from the PyTorch tensor\n",
    "#     node_features = graph_data.x  # Stay as a tensor\n",
    "#     for i, features in enumerate(node_features):\n",
    "#         G.add_node(i, features=features.tolist())  # Convert each feature to list\n",
    "\n",
    "\n",
    "#     edge_index = graph_data.edge_index.t()\n",
    "#     for edge in edge_index:\n",
    "#         G.add_edge(int(edge[0]), int(edge[1]))\n",
    "\n",
    "#     pos = nx.spring_layout(G)\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "\n",
    "#     nx.draw(G, pos, with_labels=True, node_size=500, node_color=\"lightblue\", font_size=10, font_weight=\"bold\")\n",
    "\n",
    "#     node_labels = {i: f\"{i}\" for i in G.nodes()}\n",
    "#     nx.draw_networkx_labels(G, pos, labels=node_labels)\n",
    "\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_graph(graph_train_data[20], title=\"Sample Graph Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
