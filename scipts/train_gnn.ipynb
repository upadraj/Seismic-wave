{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:28:48.439995Z",
     "start_time": "2024-10-01T03:28:44.399340Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.gnn import SeismicGNN"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:01:25.953227Z",
     "start_time": "2024-10-01T04:01:08.667345Z"
    }
   },
   "id": "ae0ec1ee186ab5fa",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(data)\n",
    "\n",
    "    # Compute loss (only on the nodes in the training set)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:31:24.880570Z",
     "start_time": "2024-10-01T03:31:24.877665Z"
    }
   },
   "id": "a0adfac494de0bb6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    logits = model(data)\n",
    "    pred = logits.argmax(dim=1)  # Get the predicted class for each node\n",
    "\n",
    "    # Compute accuracy on the train, validation, and test sets\n",
    "    train_correct = pred[data.train_mask] == data.y[data.train_mask]\n",
    "    val_correct = pred[data.val_mask] == data.y[data.val_mask]\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "\n",
    "    train_acc = int(train_correct.sum()) / int(data.train_mask.sum())\n",
    "    val_acc = int(val_correct.sum()) / int(data.val_mask.sum())\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "\n",
    "    return train_acc, val_acc, test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:31:34.077390Z",
     "start_time": "2024-10-01T03:31:34.074628Z"
    }
   },
   "id": "4c09aea70522048a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../data/processed/balance_16k/model_input/graph_with_features_and_labels.gpickle', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:37:31.953086Z",
     "start_time": "2024-10-01T03:37:18.436312Z"
    }
   },
   "id": "715df0515ac43748",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "networkx.classes.graph.Graph"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:37:34.093420Z",
     "start_time": "2024-10-01T03:37:34.089552Z"
    }
   },
   "id": "b5a827c5e21da834",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pradh\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch_geometric\\utils\\convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  data_dict[key] = torch.as_tensor(value)\n"
     ]
    }
   ],
   "source": [
    "data = from_networkx(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:50:31.329780Z",
     "start_time": "2024-10-01T03:38:01.067923Z"
    }
   },
   "id": "5f348633320269b2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(graph.number_of_nodes()):\n",
    "    graph.nodes[i]['label'] = graph.nodes[i]['label'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:58:19.568051Z",
     "start_time": "2024-10-01T03:58:19.558639Z"
    }
   },
   "id": "388dbb4c2548682a",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features shape: torch.Size([16303, 7203])\n",
      "Node labels shape: torch.Size([16303])\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    \"Pn\": 0,\n",
    "    \"S\": 1,\n",
    "    \"Lg\": 2,\n",
    "    \"Sn\": 3,\n",
    "    \"P\": 4,\n",
    "    \"Pg\": 5    \n",
    "}\n",
    "\n",
    "# Convert string labels to integers using the mapping\n",
    "numeric_labels = [label_mapping[graph.nodes[i]['label']] for i in range(graph.number_of_nodes())]\n",
    "\n",
    "# Convert to tensor\n",
    "data.x = torch.tensor([graph.nodes[i]['features'] for i in range(graph.number_of_nodes())], dtype=torch.float)\n",
    "data.y = torch.tensor(numeric_labels, dtype=torch.long)\n",
    "\n",
    "# Verify the shapes of the features and labels\n",
    "print(f\"Node features shape: {data.x.shape}\")  # Should be (num_nodes, num_features)\n",
    "print(f\"Node labels shape: {data.y.shape}\")    # Should be (num_nodes,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T03:58:57.430397Z",
     "start_time": "2024-10-01T03:58:49.762222Z"
    }
   },
   "id": "eaeec2cb6d7aa816",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train nodes: 13042, Validation nodes: 1630, Test nodes: 1631\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes in the graph\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "# Create an array of node indices (from 0 to num_nodes-1)\n",
    "node_indices = np.arange(num_nodes)\n",
    "\n",
    "# Step 1: Split into train (e.g., 70%) and temp (remaining 30%)\n",
    "train_indices, temp_indices = train_test_split(node_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Further split temp into validation (15%) and test (15%)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check the number of nodes in each set\n",
    "print(f\"Train nodes: {len(train_indices)}, Validation nodes: {len(val_indices)}, Test nodes: {len(test_indices)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:01:51.643782Z",
     "start_time": "2024-10-01T04:01:51.638985Z"
    }
   },
   "id": "15dad0617499e7a3",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "\n",
    "val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "val_mask[val_indices] = True\n",
    "\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Add the masks to the data object\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:02:06.474977Z",
     "start_time": "2024-10-01T04:02:06.450135Z"
    }
   },
   "id": "47c7b031174462bc",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 22.18 GiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 27.32 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Compute the loss using only the nodes in the training set\u001B[39;00m\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mnll_loss(out[data\u001B[38;5;241m.\u001B[39mtrain_mask], data\u001B[38;5;241m.\u001B[39my[data\u001B[38;5;241m.\u001B[39mtrain_mask])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive - University of New Mexico\\Desktop\\Fall 2024\\CS521- Data Mining\\Data_mining\\models\\gnn.py:18\u001B[0m, in \u001B[0;36mSeismicGNN.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     15\u001B[0m x, edge_index \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mx, data\u001B[38;5;241m.\u001B[39medge_index  \u001B[38;5;66;03m# node features and edge index\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# First Graph Convolutional Layer + Activation\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(x)  \u001B[38;5;66;03m# Apply ReLU non-linearity\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Second Graph Convolutional Layer (output layer)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:263\u001B[0m, in \u001B[0;36mGCNConv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m    260\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(x)\n\u001B[0;32m    262\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[1;32m--> 263\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    266\u001B[0m     out \u001B[38;5;241m=\u001B[39m out \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_5l5q50yc.py:209\u001B[0m, in \u001B[0;36mpropagate\u001B[1;34m(self, edge_index, x, edge_weight, size)\u001B[0m\n\u001B[0;32m    200\u001B[0m             kwargs \u001B[38;5;241m=\u001B[39m CollectArgs(\n\u001B[0;32m    201\u001B[0m                 x_j\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_j\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    202\u001B[0m                 edge_weight\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_weight\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m                 dim_size\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mdim_size,\n\u001B[0;32m    206\u001B[0m             )\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# End Message Forward Pre Hook #########################################\u001B[39;00m\n\u001B[1;32m--> 209\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_j\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_j\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;66;03m# Begin Message Forward Hook ###########################################\u001B[39;00m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:271\u001B[0m, in \u001B[0;36mGCNConv.message\u001B[1;34m(self, x_j, edge_weight)\u001B[0m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_j: Tensor, edge_weight: OptTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j \u001B[38;5;28;01mif\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_j\u001B[49m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 22.18 GiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 27.32 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Initialize the GNN model\n",
    "model = SeismicGNN(in_channels=data.x.shape[1], hidden_channels=64, out_channels=6)  # Adjust based on your data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "data = data.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(data)\n",
    "\n",
    "    # Compute the loss using only the nodes in the training set\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation and testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_acc, val_acc, test_acc = test(model, data)\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:07:15.822983Z",
     "start_time": "2024-10-01T04:06:51.284336Z"
    }
   },
   "id": "3eec92834f2417b1",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Print the device being used (should show 'cuda' if a GPU is available)\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:03:44.077912Z",
     "start_time": "2024-10-01T04:03:44.072856Z"
    }
   },
   "id": "60dac3ada64a085f",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "721977959349acde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
