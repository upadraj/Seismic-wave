{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.653684Z",
     "start_time": "2024-09-15T22:15:19.247066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import torchmetrics\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(r'../../Seismic-wave/')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from models.cnn import CNN\n",
    "from models.resnet import ResNet, PretrainedResNet\n",
    "from models.loss import FocalLoss\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from utils.data_utils import count_unique_colum_and_vlaues, znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.703681406Z",
     "start_time": "2024-09-10T17:58:26.382549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.704898439Z",
     "start_time": "2024-09-10T17:58:26.402346Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = np.load(\"../data/processed/balance_16k/model_input/train_features.npy\")\n",
    "train_labels = np.load(\"../data/processed/balance_16k/model_input/train_labels.npy\")\n",
    "test_features = np.load(\"../data/processed/balance_16k/model_input/test_features.npy\")\n",
    "test_labels = np.load(\"../data/processed/balance_16k/model_input/test_labels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.705572157Z",
     "start_time": "2024-09-10T17:58:26.871340Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = torch.from_numpy(train_features).float()\n",
    "train_features = train_features.to(device)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "train_labels = train_labels.to(device)\n",
    "\n",
    "test_features = torch.from_numpy(test_features).float()\n",
    "test_features = test_features.to(device)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.706834917Z",
     "start_time": "2024-09-10T17:58:27.178422Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_features = torch.nan_to_num(znorm(train_features))\n",
    "# test_features = torch.nan_to_num(znorm(test_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.707565531Z",
     "start_time": "2024-09-10T17:58:27.180315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 551.3118,  868.1703,  905.7092, 1075.3159,  999.5989,  900.5469,\n",
      "         883.9075, 1007.1663, 1023.2589,  906.7816, 1045.3395, 1050.2535,\n",
      "         796.6950, 1005.7365, 1020.4127,  893.5198, 1017.3926, 1025.4993,\n",
      "         853.3067,  881.0011,  947.5697,  971.8906, 1037.9156, 1038.0315,\n",
      "         862.0995,  944.6255, 1155.2227,  939.3242,  875.1727,  992.8647,\n",
      "         950.1880,  959.4304,  881.0698,  962.9187, 1058.3158,  984.0338,\n",
      "         878.3921, 1039.0411, 1048.5897,  975.0575,  965.7336,  994.4946,\n",
      "         893.1761,  968.9340, 1042.4004, 1086.5079,  964.2438,  832.8425,\n",
      "         408.5294,    0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_features[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.708445197Z",
     "start_time": "2024-09-10T17:58:27.247925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: torch.Size([14672, 3, 50, 50]), Train label: torch.Size([14672]) \n",
      "Test features: torch.Size([1631, 3, 50, 50]), Test label: torch.Size([1631]) \n",
      "(tensor(0., device='cuda:0'), tensor(17645068., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train features: {train_features.shape}, Train label: {train_labels.shape} \")\n",
    "print(f\"Test features: {test_features.shape}, Test label: {test_labels.shape} \")\n",
    "train_min, train_max = train_features.min(), train_features.max()\n",
    "print((train_min, train_max))\n",
    "\n",
    "# inputs = 2 * (inputs - x_min) / (x_max - x_min) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.723390596Z",
     "start_time": "2024-09-10T17:58:27.260448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 307\n",
      "1 296\n",
      "2 290\n",
      "3 281\n",
      "4 149\n",
      "5 308\n"
     ]
    }
   ],
   "source": [
    "unique_value, count = count_unique_colum_and_vlaues(test_labels.to(device='cpu'))\n",
    "for x in range(len(count)):\n",
    "    print(unique_value[x], count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.724318562Z",
     "start_time": "2024-09-10T17:58:27.263258Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = TensorDataset(train_features, train_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_features, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.725159256Z",
     "start_time": "2024-09-10T17:58:27.266090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajeshupadhayaya/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "initial_lr = 1e-4\n",
    "base_lr = 1e-4\n",
    "warmup_steps = 30\n",
    "epochs = 10\n",
    "\n",
    "model = CNN()\n",
    "model = model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# criterion = FocalLoss()\n",
    "optimizer = optim.Rprop(model.parameters(), lr=initial_lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.725844148Z",
     "start_time": "2024-09-10T17:58:27.809348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm): LSTM(512, 32, batch_first=True, dropout=0.5)\n",
       "  (fc1): Linear(in_features=373248, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.728129825Z",
     "start_time": "2024-09-10T17:58:27.813416Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    initial_lr=initial_lr,\n",
    "    base_lr=base_lr,\n",
    "):\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        if epoch < warmup_steps:\n",
    "            lr = initial_lr + (base_lr - initial_lr) * (epoch / warmup_steps)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        batch_loss = 0.0\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "        avg_loss = batch_loss / len(dataloader)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}, Cross Entropy Loss: {avg_loss:.4f}, Learning Rate: {initial_lr:.6f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.728930688Z",
     "start_time": "2024-09-10T17:58:27.817784Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 512, got 13824",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, device, criterion, optimizer, scheduler, epochs, warmup_steps, initial_lr, base_lr)\u001b[0m\n\u001b[1;32m     28\u001b[0m batch_targets \u001b[38;5;241m=\u001b[39m batch_targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[1;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Seismic-wave/models/cnn.py:47\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, height, channels \u001b[38;5;241m*\u001b[39m width)  \u001b[38;5;66;03m# Reshape to (batch, height, features)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# # Pass through LSTM\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m lstm_out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Flatten the LSTM output for fully connected layers\u001b[39;00m\n\u001b[1;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/rnn.py:898\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    894\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[1;32m    895\u001b[0m                           max_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    896\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    897\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/rnn.py:827\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    826\u001b[0m                        ):\n\u001b[0;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    829\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/seismic/lib/python3.12/site-packages/torch/nn/modules/rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 512, got 13824"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.731638773Z",
     "start_time": "2024-09-10T18:15:38.896449Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy_and_probabilities(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    class_correct = torch.zeros(num_classes)\n",
    "    class_samples = torch.zeros(num_classes)\n",
    "\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                if predictions[i] == label:\n",
    "                    class_correct[label] += 1\n",
    "                class_samples[label] += 1\n",
    "\n",
    "    y_prob = torch.cat(all_probs, dim=0)\n",
    "    y_true = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    total_accuracy = total_correct / total_samples * 100\n",
    "    class_accuracy = class_correct / class_samples * 100\n",
    "\n",
    "    return total_accuracy, class_accuracy, y_prob, y_true\n",
    "\n",
    "\n",
    "num_classes = 6\n",
    "total_accuracy, class_accuracy, y_prob, y_true = calculate_accuracy_and_probabilities(\n",
    "    model, dataloader=test_dataloader, num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(f\"Total Accuracy: {total_accuracy:.2f}%\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"Accuracy of class {i}: {class_accuracy[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.732418458Z",
     "start_time": "2024-09-09T21:32:33.044337Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_true, y_prob, n_bins=10):\n",
    "    y_true_np = y_true.cpu().numpy()\n",
    "    y_prob_np = y_prob.cpu().detach().numpy()\n",
    "\n",
    "    y_prob_max = np.max(y_prob_np, axis=1)\n",
    "\n",
    "    y_pred_max = np.argmax(y_prob_np, axis=1)\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(\n",
    "        y_true_np == y_pred_max, y_prob_max, n_bins=n_bins\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(prob_pred, prob_true, marker=\"o\", label=\"Calibration curve\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Perfect calibration (ideal)\")\n",
    "\n",
    "    plt.title(\"Calibration Plot for Multi-Class Model (Max Confidence)\")\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"True probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    brier_score = brier_score_loss(y_true_np == y_pred_max, y_prob_max)\n",
    "    print(f\"Brier score loss: {brier_score:.4f}\")\n",
    "\n",
    "\n",
    "plot_calibration_curve(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.733193919Z",
     "start_time": "2024-09-09T19:15:21.960969Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# test_dataset = TensorDataset(test_features, test_labels)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=6).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_test_inputs, batch_test_targets in test_dataloader:\n",
    "#         outputs = model(batch_test_inputs)\n",
    "#         predictions = torch.argmax(outputs, dim=1)\n",
    "#         accuracy.update(predictions, batch_test_targets)\n",
    "\n",
    "# final_accuracy = accuracy.compute().item()\n",
    "# print(f\"Accuracy on the test data: {final_accuracy * 100:.2f}%\")\n",
    "\n",
    "# accuracy.reset()\n",
    "\n",
    "\n",
    "# def lr_finder(model, criterion, optimizer, train_loader, init_value=1e-10, final_value=10, beta=0.98):\n",
    "#     num = len(train_loader) - 1\n",
    "#     mult = (final_value / init_value) ** (1/num)\n",
    "#     lr = init_value\n",
    "#     optimizer.param_groups[0]['lr'] = lr\n",
    "#     avg_loss, best_loss = 0.0, 0.0\n",
    "#     losses, log_lrs = [], []\n",
    "\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         # Move data to the correct device\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         # Zero the gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Compute the smoothed loss\n",
    "#         avg_loss = beta * avg_loss + (1 - beta) * loss.item()\n",
    "#         smoothed_loss = avg_loss / (1 - beta ** (i + 1))\n",
    "\n",
    "#         # Stop if the loss is exploding\n",
    "#         if i > 1 and smoothed_loss > 4 * best_loss:\n",
    "#             break\n",
    "\n",
    "#         # Record the best loss\n",
    "#         if smoothed_loss < best_loss or i == 0:\n",
    "#             best_loss = smoothed_loss\n",
    "\n",
    "#         # Backward pass and update the weights\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Store the values\n",
    "#         losses.append(smoothed_loss)\n",
    "#         log_lrs.append(lr)\n",
    "\n",
    "#         # Update the learning rate\n",
    "#         lr *= mult\n",
    "#         optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "#     # Plot the learning rate vs loss graph\n",
    "#     plt.plot(log_lrs, losses)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlabel(\"Learning Rate\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.show()\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-8)\n",
    "\n",
    "# lr_finder(model, criterion, optimizer, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.733885208Z",
     "start_time": "2024-09-09T19:15:21.963223Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
