{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.653684Z",
     "start_time": "2024-09-15T22:15:19.247066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import torchmetrics\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(r'../../Seismic-wave/')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from models.cnn import CNN, ImageCNN\n",
    "from models.resnet import ResNet, PretrainedResNet\n",
    "from models.loss import FocalLoss\n",
    "from torchvision import datasets,transforms\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from utils.data_utils import count_unique_colum_and_vlaues, znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.703681406Z",
     "start_time": "2024-09-10T17:58:26.382549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "initial_lr = 1e-4\n",
    "base_lr = 1e-4\n",
    "warmup_steps = 30\n",
    "epochs = 10\n",
    "\n",
    "model = ImageCNN()\n",
    "model = model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# criterion = FocalLoss()\n",
    "optimizer = optim.Rprop(model.parameters(), lr=initial_lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.704898439Z",
     "start_time": "2024-09-10T17:58:26.402346Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Time Series data loading.\n",
    "# Uncomment everything on this code shell and commnet out the code shell after this cell to run as time series data.\n",
    "\n",
    "# train_features = np.load(\"../data/processed/balance_16k/model_input/train_features.npy\")\n",
    "# train_labels = np.load(\"../data/processed/balance_16k/model_input/train_labels.npy\")\n",
    "# test_features = np.load(\"../data/processed/balance_16k/model_input/test_features.npy\")\n",
    "# test_labels= np.load(\"../data/processed/balance_16k/model_input/test_labels.npy\")\n",
    "\n",
    "# train_features = torch.from_numpy(train_features).float()\n",
    "# train_features = train_features.to(device)\n",
    "# train_labels = torch.from_numpy(train_labels)\n",
    "# train_labels = train_labels.to(device)\n",
    "\n",
    "# test_features = torch.from_numpy(test_features).float()\n",
    "# test_features = test_features.to(device)\n",
    "# test_labels = torch.from_numpy(test_labels)\n",
    "# test_labels = test_labels.to(device)\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(train_features, train_labels)\n",
    "# train_loader= DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = TensorDataset(test_features, test_labels)\n",
    "# test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "# Uncomment everything on this code shell and commnet out the code shell before this cell to run as image data.\n",
    "\n",
    "image_folder = \"../spectrogram_images/\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    \n",
    "])\n",
    "path = \"../spectrogram_images/\"\n",
    "dataset = datasets.ImageFolder(root=image_folder, transform=transform)\n",
    "\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size) \n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for both training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size= batch_size, shuffle=False)\n",
    "\n",
    "data_loader = DataLoader(dataset,batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.708445197Z",
     "start_time": "2024-09-10T17:58:27.247925Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(f\"Train features: {train_features.shape}, Train label: {train_labels.shape} \")\n",
    "# print(f\"Test features: {test_features.shape}, Test label: {test_labels.shape} \")\n",
    "# train_min, train_max = train_features.min(), train_features.max()\n",
    "# print((train_min, train_max))\n",
    "\n",
    "# unique_value, count = count_unique_colum_and_vlaues(test_labels.to(device='cpu'))\n",
    "# for x in range(len(count)):\n",
    "#     print(unique_value[x], count[x])\n",
    "\n",
    "# print(train_features[0][0][0])\n",
    "# # inputs = 2 * (inputs - x_min) / (x_max - x_min) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:15:28.728129825Z",
     "start_time": "2024-09-10T17:58:27.813416Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    initial_lr=initial_lr,\n",
    "    base_lr=base_lr,\n",
    "):\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        if epoch < warmup_steps:\n",
    "            lr = initial_lr + (base_lr - initial_lr) * (epoch / warmup_steps)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        batch_loss = 0.0\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "        avg_loss = batch_loss / len(train_dataset)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs}, Cross Entropy Loss: {avg_loss:.4f}, Learning Rate: {initial_lr:.6f}\"\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy_and_probabilities(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    class_correct = torch.zeros(num_classes)\n",
    "    class_samples = torch.zeros(num_classes)\n",
    "\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                if predictions[i] == label:\n",
    "                    class_correct[label] += 1\n",
    "                class_samples[label] += 1\n",
    "\n",
    "    y_prob = torch.cat(all_probs, dim=0)\n",
    "    y_true = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    total_accuracy = total_correct / total_samples * 100\n",
    "    class_accuracy = class_correct / class_samples * 100\n",
    "\n",
    "    return total_accuracy, class_accuracy, y_prob, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageCNN(\n",
       "  (conv1): Conv2d(3, 128, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3))\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=492032, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Cross Entropy Loss: 0.0815, Learning Rate: 0.000100\n",
      "Epoch 2/10, Cross Entropy Loss: 0.0818, Learning Rate: 0.000100\n",
      "Epoch 3/10, Cross Entropy Loss: 0.0634, Learning Rate: 0.000100\n",
      "Epoch 4/10, Cross Entropy Loss: 0.0624, Learning Rate: 0.000100\n",
      "Epoch 5/10, Cross Entropy Loss: 0.0576, Learning Rate: 0.000100\n",
      "Epoch 6/10, Cross Entropy Loss: 0.0481, Learning Rate: 0.000100\n",
      "Epoch 7/10, Cross Entropy Loss: 0.0421, Learning Rate: 0.000100\n",
      "Epoch 8/10, Cross Entropy Loss: 0.0384, Learning Rate: 0.000100\n",
      "Epoch 9/10, Cross Entropy Loss: 0.0330, Learning Rate: 0.000100\n",
      "Epoch 10/10, Cross Entropy Loss: 0.0267, Learning Rate: 0.000100\n",
      "Total Accuracy: 35.00%\n",
      "Accuracy of class 0: 0.00%\n",
      "Accuracy of class 1: 50.00%\n",
      "Accuracy of class 2: 50.00%\n",
      "Accuracy of class 3: 33.33%\n",
      "Accuracy of class 4: 0.00%\n",
      "Accuracy of class 5: 50.00%\n"
     ]
    }
   ],
   "source": [
    "train_model()\n",
    "num_classes = 6\n",
    "total_accuracy, class_accuracy, y_prob, y_true = calculate_accuracy_and_probabilities(\n",
    "    model, dataloader=test_loader, num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(f\"Total Accuracy: {total_accuracy:.2f}%\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"Accuracy of class {i}: {class_accuracy[i]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "saved_model_pth = \"../trained_models/Image_CNN.pth\"\n",
    "torch.save(model, saved_model_pth)\n",
    "\n",
    "# loading the saved model\n",
    "# model = torch.load(saved_model_pth)\n",
    "\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
