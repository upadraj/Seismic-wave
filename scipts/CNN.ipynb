{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "initial_lr = 0.0008  \n",
    "base_lr = 0.0008  \n",
    "warmup_steps = 10 \n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load(\"../data/processed/balance_16k/model_input/train_features.npy\")\n",
    "train_labels = np.load(\"../data/processed/balance_16k/model_input/train_labels.npy\")\n",
    "\n",
    "test_features = np.load(\"../data/processed/balance_16k/model_input/test_features.npy\")\n",
    "test_labels = np.load(\"../data/processed/balance_16k/model_input/test_labels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.from_numpy(train_features).float()\n",
    "train_features = train_features.to(device)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "train_labels = train_labels.to(device)\n",
    "\n",
    "test_features = torch.from_numpy(test_features).float()\n",
    "test_features = test_features.to(device)\n",
    "test_labels = torch.from_numpy(test_labels)\n",
    "test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: torch.Size([14672, 3, 50, 50]), Train label: torch.Size([14672]) \n",
      "Test features: torch.Size([1631, 3, 50, 50]), Test label: torch.Size([1631]) \n",
      "(tensor(0., device='cuda:0'), tensor(13373320., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train features: {train_features.shape}, Train label: {train_labels.shape} \")\n",
    "print(f\"Test features: {test_features.shape}, Test label: {test_labels.shape} \")\n",
    "train_min, train_max = train_features.min(), train_features.max()\n",
    "print((train_min, train_max))\n",
    "\n",
    "# inputs = 2 * (inputs - x_min) / (x_max - x_min) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(train_features, train_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=2, padding=1)\n",
    "        # self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=2, padding=1\n",
    "        )\n",
    "        # self.bn2 = nn.BatchNorm2d(64)  # Add BatchNorm after the second conv layer\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=128, kernel_size=2, padding=1\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # self.bn3 = nn.BatchNorm2d(128)  # Add BatchNorm after the third conv layer\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu((self.conv1(x))))  # Conv1 -> -> leaky_relu -> Pool\n",
    "        x = self.pool(F.tanh((self.conv2(x))))  # Conv2 -> BN -> Tanh -> Pool\n",
    "        x = self.pool(F.tanh((self.conv3(x))))  # Conv3 -> BN -> Tanh -> Pool\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.tanh(self.bn_fc1(self.fc1(x)))  # FC1 -> BN -> Tanh\n",
    "        x = F.tanh(self.bn_fc2(self.fc2(x)))  # FC2 -> BN -> Tanh\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Cross Entropy Loss: 1.2336,Learningrate:  0.000800\n",
      "Epoch 2/30, Cross Entropy Loss: 1.1718,Learningrate:  0.000800\n",
      "Epoch 3/30, Cross Entropy Loss: 1.1443,Learningrate:  0.000800\n",
      "Epoch 4/30, Cross Entropy Loss: 1.1192,Learningrate:  0.000800\n",
      "Epoch 5/30, Cross Entropy Loss: 1.0958,Learningrate:  0.000800\n",
      "Epoch 6/30, Cross Entropy Loss: 1.0765,Learningrate:  0.000800\n",
      "Epoch 7/30, Cross Entropy Loss: 1.0565,Learningrate:  0.000800\n",
      "Epoch 8/30, Cross Entropy Loss: 1.0385,Learningrate:  0.000800\n",
      "Epoch 9/30, Cross Entropy Loss: 1.0197,Learningrate:  0.000800\n",
      "Epoch 10/30, Cross Entropy Loss: 1.0043,Learningrate:  0.000800\n",
      "Epoch 11/30, Cross Entropy Loss: 0.9889,Learningrate:  0.000800\n",
      "Epoch 12/30, Cross Entropy Loss: 0.9795,Learningrate:  0.000800\n",
      "Epoch 13/30, Cross Entropy Loss: 0.9617,Learningrate:  0.000800\n",
      "Epoch 14/30, Cross Entropy Loss: 0.9492,Learningrate:  0.000800\n",
      "Epoch 15/30, Cross Entropy Loss: 0.9388,Learningrate:  0.000800\n",
      "Epoch 16/30, Cross Entropy Loss: 0.9250,Learningrate:  0.000800\n",
      "Epoch 17/30, Cross Entropy Loss: 0.9149,Learningrate:  0.000800\n",
      "Epoch 18/30, Cross Entropy Loss: 0.8989,Learningrate:  0.000800\n",
      "Epoch 19/30, Cross Entropy Loss: 0.8915,Learningrate:  0.000800\n",
      "Epoch 20/30, Cross Entropy Loss: 0.8793,Learningrate:  0.000080\n",
      "Epoch 21/30, Cross Entropy Loss: 0.8678,Learningrate:  0.000080\n",
      "Epoch 22/30, Cross Entropy Loss: 0.8617,Learningrate:  0.000080\n",
      "Epoch 23/30, Cross Entropy Loss: 0.8540,Learningrate:  0.000080\n",
      "Epoch 24/30, Cross Entropy Loss: 0.8428,Learningrate:  0.000080\n",
      "Epoch 25/30, Cross Entropy Loss: 0.8388,Learningrate:  0.000080\n",
      "Epoch 26/30, Cross Entropy Loss: 0.8238,Learningrate:  0.000080\n",
      "Epoch 27/30, Cross Entropy Loss: 0.8155,Learningrate:  0.000080\n",
      "Epoch 28/30, Cross Entropy Loss: 0.8051,Learningrate:  0.000080\n",
      "Epoch 29/30, Cross Entropy Loss: 0.7999,Learningrate:  0.000080\n",
      "Epoch 30/30, Cross Entropy Loss: 0.7871,Learningrate:  0.000008\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model = model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Rprop(model.parameters(), lr=0.0008)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    p_lr = \"\"\n",
    "    \n",
    "    if epoch < warmup_steps:\n",
    "        lr = initial_lr + (base_lr - initial_lr) * (epoch / warmup_steps)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        # print(f\"Warmup Epoch {epoch+1}/{warmup_steps}, Learning Rate: {lr:.8f}\")\n",
    "    else:\n",
    "        # After warmup, allow the scheduler to control the learning rate\n",
    "        scheduler.step()  # Step the scheduler after each epoch\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group[\"lr\"]  # Get the current learning rate from the scheduler\n",
    "    # print(f\"Epoch {epoch+1}/{epochs}, Learning Rate: {lr:.8f}\")\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    for batch_inputs, batch_targets in dataloader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = batch_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Cross Entropy Loss: {avg_loss:.4f},Learningrate: {lr: 0.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: 68.55%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_dataset = TensorDataset(test_features, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=6).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_test_inputs, batch_test_targets in test_dataloader:\n",
    "        outputs = model(batch_test_inputs)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        accuracy.update(predictions, batch_test_targets)\n",
    "\n",
    "final_accuracy = accuracy.compute().item()\n",
    "print(f\"Accuracy on the test data: {final_accuracy * 100:.2f}%\")\n",
    "\n",
    "accuracy.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
