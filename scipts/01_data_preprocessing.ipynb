{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:40.299750Z",
     "start_time": "2024-09-10T17:46:38.242135Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(r'C:\\Users\\pradh\\OneDrive - University of New Mexico\\Desktop\\Fall 2024\\CS521- Data Mining\\Data_mining')))\n",
    "\n",
    "from utils.data_utils import (\n",
    "    test_train_split,\n",
    "    split_3_channel,\n",
    "    short_time_fourier_transform,\n",
    "    integer_label,\n",
    "    count_unique_colum_and_vlaues\n",
    ")\n",
    "\n",
    "from utils.augment_data import augment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:40.302415Z",
     "start_time": "2024-09-10T17:46:40.299750Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_path = \"../data/processed/balance_16k/preprocessing/x_train.csv\"\n",
    "label_path = \"../data/processed/balance_16k/preprocessing/y_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv(feature_path)\n",
    "label_df = pd.read_csv(label_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:50.345443Z",
     "start_time": "2024-09-10T17:46:40.302415Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['S'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train, test = test_train_split(df, label_df, split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:50.630444Z",
     "start_time": "2024-09-10T17:46:50.345443Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Create empty lists to store augmented data and labels\n",
    "# augmented_data = []\n",
    "# augmented_labels = []\n",
    "# \n",
    "# # Step 1: Loop through each unique label\n",
    "# for target_class in unique_classes:\n",
    "#     \n",
    "#     # Isolate the target class\n",
    "#     target_indices = np.where(label_df['labels'] == target_class)[0]\n",
    "# \n",
    "#     data_to_augment = df.iloc[target_indices]\n",
    "#     labels_to_augment = label_df.iloc[target_indices]\n",
    "#     \n",
    "#     # Augment each sample in the target class\n",
    "#     for i in range(data_to_augment.shape[0]):\n",
    "#         augmented_sample = data_to_augment.iloc[i].copy().to_numpy()\n",
    "#         \n",
    "#         # Apply augmentations\n",
    "#         augmented_sample = add_noise(augmented_sample, noise_level=0.05)\n",
    "#         \n",
    "#         if target_class == 'S':\n",
    "#             augmented_sample = scale_amplitude(augmented_sample, scale_factor=1.5)\n",
    "#         else:\n",
    "#             augmented_sample = scale_amplitude(augmented_sample, scale_factor=1.2)\n",
    "#         \n",
    "#         # Add the augmented sample and label to the lists\n",
    "#         augmented_data.append(augmented_sample)\n",
    "#         augmented_labels.append(target_class)\n",
    "# \n",
    "# # Step 2: Convert augmented data and labels to DataFrame\n",
    "# augmented_data_df = pd.DataFrame(augmented_data, columns=df.columns)\n",
    "# augmented_labels_df = pd.DataFrame(augmented_labels, columns=['labels'])  # Replace 'S' with the label column name\n",
    "# \n",
    "# # Step 3: Reintegrate augmented data into the original dataset\n",
    "# train_features = pd.concat([df, augmented_data_df], axis=0)\n",
    "# train_labels = pd.concat([label_df, augmented_labels_df], axis=0)\n",
    "# \n",
    "# # Step 4: Reset indices after concatenation to avoid index issues\n",
    "# train_features = train_features.reset_index(drop=True)\n",
    "# train_labels = train_labels.reset_index(drop=True)\n",
    "# \n",
    "# # Check final shape to verify augmentation\n",
    "# print(\"Original dataset shape:\", df.shape)\n",
    "# print(\"Augmented dataset shape:\", train_features.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:50.633582Z",
     "start_time": "2024-09-10T17:46:50.631447Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (14672, 7203)\n",
      "Augmented dataset shape: (17372, 7203)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = augment_data(train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:54.775038Z",
     "start_time": "2024-09-10T17:46:50.633582Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_features['labels'] = train_labels['labels']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:46:54.779508Z",
     "start_time": "2024-09-10T17:46:54.775038Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "s_train_features, train_labels = split_3_channel(train_features)\n",
    "s_test_features, test_labels = split_3_channel(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:32:19.121983Z",
     "start_time": "2024-09-10T17:30:25.204527Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lg' 'Pn' 'P' ... 'S' 'S' 'S']\n",
      "Label Mapping: {'Lg': 0, 'P': 1, 'Pg': 2, 'Pn': 3, 'S': 4, 'Sn': 5}\n",
      "Label Mapping: {'Lg': 0, 'P': 1, 'Pg': 2, 'Pn': 3, 'S': 4, 'Sn': 5}\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "train_labels = integer_label(train_labels)\n",
    "test_labels = integer_label(test_labels)\n",
    "\n",
    "train_features = short_time_fourier_transform(data=s_train_features)\n",
    "test_features = short_time_fourier_transform(data=s_test_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-10T17:32:26.544960Z",
     "start_time": "2024-09-10T17:32:19.121983Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:32:30.712012Z",
     "start_time": "2024-09-10T17:32:29.036694Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"../data/processed/balance_16k/model_input/train_features.npy\", train_features)\n",
    "np.save(\"../data/processed/balance_16k/model_input/train_labels.npy\", train_labels)\n",
    "\n",
    "np.save(\"../data/processed/balance_16k/model_input/test_features.npy\", test_features)\n",
    "np.save(\"../data/processed/balance_16k/model_input/test_labels.npy\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:32:35.620448Z",
     "start_time": "2024-09-10T17:32:35.617467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (29344, 3, 50, 50), Train label: torch.Size([29344]) \n",
      "Test features: (1631, 3, 50, 50), Test label: torch.Size([1631]) \n"
     ]
    }
   ],
   "source": [
    "print(f\"Train features: {train_features.shape}, Train label: {train_labels.shape} \")\n",
    "print(f\"Test features: {test_features.shape}, Test label: {test_labels.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T17:32:36.025129Z",
     "start_time": "2024-09-10T17:32:36.021712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5414\n",
      "1 5382\n",
      "2 5402\n",
      "3 5388\n",
      "4 2322\n",
      "5 5436\n"
     ]
    }
   ],
   "source": [
    "unique_value, count = count_unique_colum_and_vlaues(train_labels)\n",
    "for x in range(len(count)):\n",
    "    print(unique_value[x], count[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T03:49:05.886871Z",
     "start_time": "2024-09-10T03:49:05.884874Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
