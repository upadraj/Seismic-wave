{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"./data/balanced/input_data.npy\")\n",
    "labels = np.load(\"./data/balanced/label_data.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x)\n",
    "x_t = x_tensor.view(-1, 3, 49, 49)\n",
    "inputs = x_t.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Lg': 0, 'P': 1, 'Pg': 2, 'Pn': 3, 'S': 4, 'Sn': 5}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = np.unique(labels)\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "integer_labels = np.array([label_mapping[label] for label in labels])\n",
    "targets = torch.from_numpy(integer_labels)\n",
    "targets = targets.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_min = inputs.min()\n",
    "# x_max = inputs.max()\n",
    "# print((x_min, x_max))\n",
    "\n",
    "# inputs = 100 * (inputs - x_min) / (x_max - x_min) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.pool(F.tanh(self.conv1(x)))  # torch.Size([13042, 16, 24, 24])\n",
    "        conv2 = self.pool(F.tanh(self.conv2(conv1)))  # torch.Size([13042, 32, 12, 12])\n",
    "        conv3 = self.pool(F.tanh(self.conv3(conv2)))  # torch.Size([13042, 64, 6, 6])\n",
    "\n",
    "        flatten = conv3.view(-1, 64 * 6 * 6)\n",
    "\n",
    "        fc1 = F.tanh(self.fc1(flatten))\n",
    "        fc2 = F.tanh(self.fc2(fc1))\n",
    "\n",
    "        return fc2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
    "\n",
    "warmup_steps = 5\n",
    "epochs = 1000\n",
    "\n",
    "schedular = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model = model.to(device=device)\n",
    "inputs = inputs.to(device=device)\n",
    "targets = targets.to(device=device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # if epoch > and epoch > warmup_steps:\n",
    "    #     warmup_lr = 0.001 * (epoch + 1) / warmup_steps\n",
    "    #     for param_group in optimizer.param_groups:\n",
    "    #         param_group['lr'] = warmup_lr\n",
    "    # else:\n",
    "    #     schedular.step()\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Cross Entropy Loss: {loss.item()}, Learning Rate: {current_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Lg': 0, 'P': 1, 'Pg': 2, 'Pn': 3, 'S': 4, 'Sn': 5}\n"
     ]
    }
   ],
   "source": [
    "x = np.load(\"./data/balanced/test_data.npy\")\n",
    "labels = np.load(\"./data/balanced/test_label_data.npy\", allow_pickle=True)\n",
    "\n",
    "x_tensor = torch.from_numpy(x)\n",
    "x_t = x_tensor.view(-1, 3, 49, 49)\n",
    "inputs = x_t.float()\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "integer_labels = np.array([label_mapping[label] for label in labels])\n",
    "targets = torch.from_numpy(integer_labels)\n",
    "targets = targets.long()\n",
    "targets = targets.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = F.softmax(y_pred, dim=1)\n",
    "\n",
    "# Get the predicted class with the highest probability\n",
    "predicted_class = torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 1,  ..., 4, 5, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predicted_class = predicted_class.to(device=device)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric  = torchmetrics.Accuracy(task=\"multiclass\", num_classes=6).to(device=device)\n",
    "accuracy = accuracy_metric(predicted_class, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4440, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
